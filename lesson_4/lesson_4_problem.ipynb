{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-LAB SESSION 3: Markov Decision Process\n",
    "\n",
    "In the third session we will work on the Markov decision process (MDP)\n",
    "\n",
    "## Lava environments\n",
    "The environments used are LavaFloor (visible in the figure) and its variations.\n",
    "\n",
    "![Lava](images/lava.png)\n",
    "\n",
    "The agent starts in cell $(0, 0)$ and has to reach the treasure in $(2, 3)$. In addition to the walls of the previous environments, the floor is covered with lava, there is a black pit of death.\n",
    "\n",
    "Moreover, the agent can't comfortably perform its actions that instead have a stochastic outcome (visible in the figure):\n",
    "\n",
    "![Dynact](images/dynact.png)\n",
    "\n",
    "The action dynamics is the following:\n",
    "- $P(0.8)$ of moving in the desired direction\n",
    "- $P(0.1)$ of moving in a direction 90Â° with respect to the desired direction\n",
    "\n",
    "Finally, since the floor is covered in lava, the agent receives a negative reward for each of its steps!\n",
    "\n",
    "- -0.04 for each lava cell (L)\n",
    "- -5 for the black pit (P). \n",
    "- +1 for the treasure (G). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('../tools'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import gym, envs\n",
    "from utils.ai_lab_functions import *\n",
    "from timeit import default_timer as timer\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Properties \n",
    "\n",
    "In addition to the varables of the environments you have been using in the previous sessions, there are also a few more:\n",
    "\n",
    "- $T$: matrix of the transition function $T(s, a, s') \\rightarrow [0, 1]$\n",
    "- $RS$: matrix of the reward function $R(s) \\rightarrow \\mathbb{R}$\n",
    "\n",
    "The available actions are still Left, Right, Up, Down.\n",
    "\n",
    "#### Code Hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions:  4\n",
      "Actions:  {0: 'L', 1: 'R', 2: 'U', 3: 'D'}\n",
      "Reward of starting state: -0.04\n",
      "Reward of goal state: 1.0\n",
      "Reward:\n",
      " [[-0.04 -0.04 -0.04 -0.04]\n",
      " [-0.04  0.   -0.04 -5.  ]\n",
      " [-0.04 -0.04 -0.04  1.  ]]\n",
      "Probability from (0, 0) to (0, 1) with action right: 0.8\n",
      "Probability from (0, 0) to (2, 3) with action right: 0.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"LavaFloor-v0\")\n",
    "\n",
    "current_state = env.pos_to_state(0, 0)\n",
    "next_state = env.pos_to_state(0, 1)\n",
    "goal_state = env.pos_to_state(2, 3)\n",
    "\n",
    "print(\"Number of actions: \", env.action_space.n)\n",
    "print(\"Actions: \", env.actions)\n",
    "print(\"Reward of starting state:\", env.RS[current_state])\n",
    "print(\"Reward of goal state:\", env.RS[goal_state])\n",
    "print(\"Reward:\\n\", np.asarray(env.RS).reshape(env.rows, env.cols))\n",
    "print(\"Probability from (0, 0) to (0, 1) with action right:\", env.T[current_state, 1, next_state])\n",
    "print(\"Probability from (0, 0) to (2, 3) with action right:\", env.T[current_state, 1, goal_state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1: Value Iteration Algorithm\n",
    "\n",
    "Your first assignment is to implement the Value Iteration algorithm on LavaFloor. The solution returned by your algorithm must be a 1-d array of action identifiers where the $i$-th action refers to the $i$-th state.  You can perform all the test on different versions of the environment, but with the same structure: *HugeLavaFloor*, *NiceLavaFloor* and *VeryBadLavaFloor*.\n",
    "\n",
    "<img src=\"images/value-iteration.png\" width=\"600\">\n",
    "\n",
    "You must implement the *value_iteration* function. Notice that the value iteration approach return a matrix with the value for eacht state, the function *values_to_policy* automatically convert this matrix in the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_iteration(environment, maxiters=300, discount=0.9, max_error=1e-3):\n",
    "    \"\"\"\n",
    "    Performs the value iteration algorithm for a specific environment\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        maxiters: timeout for the iterations\n",
    "        discount: gamma value, the discount factor for the Bellman equation\n",
    "        max_error: the maximum error allowd in the utility of any state\n",
    "        \n",
    "    Returns:\n",
    "        policy: 1-d dimensional array of action identifiers where index `i` corresponds to state id `i`\n",
    "    \"\"\"\n",
    "    \n",
    "    U_1 = [0 for _ in range(environment.observation_space.n)] # vector of utilities for states S\n",
    "    delta = 0 # maximum change in the utility o any state in an iteration\n",
    "    U = U_1.copy()\n",
    "    #\n",
    "    # Code Here!\n",
    "    #\n",
    "    return values_to_policy(np.asarray(U), env) # automatically convert the value matrix U to a policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code executes and Value Iteration and prints the resulting policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tEnvironment: LavaFloor-v0 \n",
      "\tValue Iteration\n",
      "----------------------------------------------------------------\n",
      "\n",
      "RENDER:\n",
      "[['S' 'L' 'L' 'L']\n",
      " ['L' 'W' 'L' 'P']\n",
      " ['L' 'L' 'L' 'G']]\n",
      "\n",
      "TIME: \n",
      "0.0011\n",
      "\n",
      "POLICY:\n",
      "[['L' 'L' 'L' 'L']\n",
      " ['L' 'L' 'L' 'L']\n",
      " ['L' 'L' 'L' 'L']]\n"
     ]
    }
   ],
   "source": [
    "envname = \"LavaFloor-v0\"\n",
    "#envname = \"HugeLavaFloor-v0\"\n",
    "#envname = \"NiceLavaFloor-v0\"\n",
    "#envname = \"VeryBadLavaFloor-v0\"\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tEnvironment: {} \\n\\tValue Iteration\".format(envname))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "env = gym.make(envname)\n",
    "print(\"\\nRENDER:\")\n",
    "env.render()\n",
    "\n",
    "t = timer()\n",
    "policy = value_iteration(env)\n",
    "\n",
    "print(\"\\nTIME: \\n{}\".format(round(timer() - t, 4)))\n",
    "print(\"\\nPOLICY:\")\n",
    "print(np.vectorize(env.actions.get)(policy.reshape(env.rows, env.cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results can be found [here](lesson_3_results.txt).\n",
    "\n",
    "### Assignment 2: Policy Iteration Algorithm\n",
    "\n",
    "Your first assignment is to implement the Policy Iteration algorithm on LavaFloor. The solution returned by your algorithm must be a 1-d array of action identifiers where the $i$-th action refers to the $i$-th state. You can perform all the test on different versions of the environment, but with the same structure: *HugeLavaFloor*, *NiceLavaFloor* and *VeryBadLavaFloor*.\n",
    "\n",
    "<img src=\"images/policy-iteration.png\" width=\"600\">\n",
    "\n",
    "For the *policy evaluation step*, implement this function repeating the update for an arbitrary number of steps (e.g., 10):\n",
    "\n",
    "<img src=\"images/policy-evaluating.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_iteration(environment, maxiters=300, discount=0.9, maxviter=10):\n",
    "    \"\"\"\n",
    "    Performs the policy iteration algorithm for a specific environment\n",
    "    \n",
    "    Args:\n",
    "        environment: OpenAI Gym environment\n",
    "        maxiters: timeout for the iterations\n",
    "        discount: gamma value, the discount factor for the Bellman equation\n",
    "        \n",
    "    Returns:\n",
    "        policy: 1-d dimensional array of action identifiers where index `i` corresponds to state id `i`\n",
    "    \"\"\"\n",
    "    \n",
    "    policy = [0 for _ in range(environment.observation_space.n)] #initial policy\n",
    "    U = [0 for _ in range(environment.observation_space.n)] #utility array\n",
    "\n",
    "    # Step (1): Policy Evaluation\n",
    "    #\n",
    "    # Code Here!\n",
    "    #\n",
    "    \n",
    "    # Step (2) Policy Improvement\n",
    "    unchanged = True  \n",
    "    #\n",
    "    # Code Here!\n",
    "    #\n",
    "    \n",
    "    return np.asarray(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code executes and Value Iteration and prints the resulting policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------\n",
      "\tEnvironment: LavaFloor-v0 \n",
      "\tPolicy Iteration\n",
      "----------------------------------------------------------------\n",
      "\n",
      "RENDER:\n",
      "[['S' 'L' 'L' 'L']\n",
      " ['L' 'W' 'L' 'P']\n",
      " ['L' 'L' 'L' 'G']]\n",
      "\n",
      "TIME: \n",
      "0.0001\n",
      "\n",
      "POLICY:\n",
      "[['L' 'L' 'L' 'L']\n",
      " ['L' 'L' 'L' 'L']\n",
      " ['L' 'L' 'L' 'L']]\n"
     ]
    }
   ],
   "source": [
    "envname = \"LavaFloor-v0\"\n",
    "#envname = \"HugeLavaFloor-v0\"\n",
    "#envname = \"NiceLavaFloor-v0\"\n",
    "#envname = \"VeryBadLavaFloor-v0\"\n",
    "\n",
    "print(\"\\n----------------------------------------------------------------\")\n",
    "print(\"\\tEnvironment: {} \\n\\tPolicy Iteration\".format(envname))\n",
    "print(\"----------------------------------------------------------------\")\n",
    "\n",
    "env = gym.make(envname)\n",
    "print(\"\\nRENDER:\")\n",
    "env.render()\n",
    "\n",
    "t = timer()\n",
    "policy = policy_iteration(env)\n",
    "\n",
    "print(\"\\nTIME: \\n{}\".format(round(timer() - t, 4)))\n",
    "print(\"\\nPOLICY:\")\n",
    "print(np.vectorize(env.actions.get)(policy.reshape(env.rows, env.cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results can be found [here](lesson_3_results.txt).\n",
    "\n",
    "### Comparison\n",
    "\n",
    "The following code performs a comparison between Value Iteration and Policy Iteration, by plotting the accumulated rewards of each episode with iterations in range $[1, 50]$ (might take a long time on big environments). You can perform all the test on a different versions of the environment, but with the same structure: *HugeLavaFloor*.\n",
    "\n",
    "The function **run_episode(envirnonment, policy, max_iteration)** run an episode on the given environment using the input policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Value Iteration: 100%|âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 51/51 [00:01<00:00, 32.44it/s]\n",
      "Policy Iteration: 100%|ââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ| 51/51 [00:01<00:00, 33.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 3.1148s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "envname = \"LavaFloor-v0\"\n",
    "#envname = \"HugeLavaFloor-v0\"\n",
    "\n",
    "maxiters = 50\n",
    "\n",
    "env = gym.make(envname)\n",
    "\n",
    "series = []  # Series of learning rates to plot\n",
    "liters = np.arange(maxiters + 1)  # Learning iteration values\n",
    "liters[0] = 1\n",
    "elimit = 100  # Limit of steps per episode\n",
    "rep = 10  # Number of repetitions per iteration value\n",
    "virewards = np.zeros(len(liters))  # Rewards array\n",
    "c = 0\n",
    "\n",
    "t = timer()\n",
    "\n",
    "# Value iteration\n",
    "for i in tqdm(liters, desc=\"Value Iteration\", leave=True):\n",
    "    reprew = 0\n",
    "    policy = value_iteration(env, maxiters=i)  # Compute policy\n",
    "    # Repeat multiple times and compute mean reward\n",
    "    for _ in range(rep):\n",
    "        reprew += run_episode(env, policy, elimit)  # Execute policy\n",
    "    virewards[c] = reprew / rep\n",
    "    c += 1\n",
    "series.append({\"x\": liters, \"y\": virewards, \"ls\": \"-\", \"label\": \"Value Iteration\"})\n",
    "\n",
    "vmaxiters = 5  # Max number of iterations to perform while evaluating a policy\n",
    "pirewards = np.zeros(len(liters))  # Rewards array\n",
    "c = 0\n",
    "\n",
    "# Policy iteration\n",
    "for i in tqdm(liters, desc=\"Policy Iteration\", leave=True):\n",
    "    reprew = 0\n",
    "    policy = policy_iteration(env, maxiters=i)  # Compute policy\n",
    "    # Repeat multiple times and compute mean reward\n",
    "    for _ in range(rep):\n",
    "        reprew += run_episode(env, policy, elimit)  # Execute policy\n",
    "    pirewards[c] = reprew / rep\n",
    "    c += 1\n",
    "series.append({\"x\": liters, \"y\": pirewards, \"ls\": \"-\", \"label\": \"Policy Iteration\"})\n",
    "\n",
    "print(\"Execution time: {0}s\".format(round(timer() - t, 4)))\n",
    "np.set_printoptions(linewidth=10000)\n",
    "\n",
    "plot(series, \"Learning Rate\", \"Iterations\", \"Reward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct results for comparison can be found here below. Notice that since the executions are stochastic the charts could differ: the important thing is the global trend and the final convergence to an optimal solution.\n",
    "\n",
    "**Standard Lava Floore results comparison**\n",
    "<img src=\"images/results-standard.png\" width=\"600\">\n",
    "\n",
    "**Huge Lava Floore results comparison**\n",
    "<img src=\"images/results-huge.png\" width=\"600\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
